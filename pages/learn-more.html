<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learn More • Museum of AI</title>
    <link href="https://fonts.googleapis.com/css2?family=Exo+2:wght@300;400;600;700;900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="../assets/css/tailwind.css">

    <link rel="stylesheet" href="../assets/css/styles.css">
</head>
<body>
    <header class="w-full">
        <div class="container mx-auto px-4 py-6">
            <a href="../index.html" class="text-slate-300 hover:text-white">← Back to Home</a>
        </div>
    </header>
    <main class="py-16">
        <div class="container mx-auto px-4">
            <h1 class="text-4xl font-bold mb-6">Some of the major issues</h1>
            <p class="text-slate-300 mb-8">What can go right and what can go wrong.</p>

            <div class="space-y-8">
                <section class="glass-card p-6 rounded-xl">
                    <h2 class="text-2xl font-bold mb-4">Healthcare Diagnostics</h2>
                    <p class="text-emerald-300 mb-3">AI brings powerful advantages to healthcare by spotting patterns that human eyes often miss. Algorithms can scan X-rays, MRIs, or lab results in seconds, flagging potential problems long before they become critical. This not only helps doctors save time but also expands access to expert-level diagnostics in areas with limited healthcare resources. The result is earlier treatment, fewer errors, and better outcomes for patients.</p>
                    <p class="text-rose-300">On the other hand, AI in healthcare raises concerns around accuracy, trust, and bias. A model trained on limited or skewed data might miss diagnoses for certain populations, worsening existing health disparities. There are also ethical and legal questions: who is responsible if an AI-driven diagnosis is wrong—the doctor, the developer, or the hospital? Privacy is another issue, since training these systems requires enormous amounts of sensitive personal data.</p>
                </section>

                <section class="glass-card p-6 rounded-xl">
                    <h2 class="text-2xl font-bold mb-4">Energy Use</h2>
                    <p class="text-emerald-300 mb-3">AI offers huge potential for more sustainable energy systems. By analyzing real-time data, it can optimize how electricity flows through smart grids, balance renewable energy sources like wind and solar, and predict demand to reduce waste. For industries and households alike, AI can recommend efficiency measures, lowering costs while cutting carbon emissions.</p>
                    <p class="text-rose-300">But relying on AI for energy management also comes with challenges. Complex systems are vulnerable to cyberattacks, which could disrupt entire grids. Moreover, AI requires large amounts of computational power, which itself consumes energy and may offset some of its benefits. Decisions about which energy uses to prioritize could also become political, raising questions about fairness and control.</p>
                </section>

                <section class="glass-card p-6 rounded-xl">
                    <h2 class="text-2xl font-bold mb-4">AI Companionship</h2>
                    <p class="text-emerald-300 mb-3">AI companions can provide comfort, conversation, and emotional support to those who might otherwise feel isolated. For the elderly, people with disabilities, or even busy professionals, AI can offer companionship at any time of day, learning personal preferences and adapting to moods. These systems may even help reduce loneliness and contribute to better mental health.</p>
                    <p class="text-rose-300">Still, AI companionship raises deep concerns about authenticity and dependency. Relationships with machines, however realistic, are not the same as human bonds and may discourage people from seeking real social connections. There is also the danger of commercialization—where “companions” are subtly designed to influence users’ decisions, from shopping to politics. This blurring of intimacy and manipulation is a major ethical risk.</p>
                </section>

                <section class="glass-card p-6 rounded-xl">
                    <h2 class="text-2xl font-bold mb-4">Autonomous Systems</h2>
                    <p class="text-emerald-300 mb-3">Autonomous systems like self-driving cars, delivery drones, and industrial robots promise efficiency, safety, and new levels of convenience. They can reduce traffic accidents caused by human error, streamline logistics, and operate in dangerous environments where humans cannot safely go. For society, this means lower costs, increased productivity, and potentially safer roads and workplaces.</p>
                    <p class="text-rose-300">The downsides include the displacement of jobs and the difficulty of assigning accountability when things go wrong. If an autonomous car causes an accident, who bears the blame—the manufacturer, the software developer, or the passenger? Ethical dilemmas also arise, such as how machines should be programmed to act in life-or-death situations. Widespread adoption also depends on updating laws and infrastructure, which lag far behind the technology.</p>
                </section>

                <section class="glass-card p-6 rounded-xl">
                    <h2 class="text-2xl font-bold mb-4">Education and AI</h2>
                    <p class="text-emerald-300 mb-3">AI has the potential to revolutionize education by creating personalized learning paths that adapt to each student’s strengths and weaknesses. Automated tutors can provide instant feedback, track progress, and free up teachers to focus more on human interaction. Administrative tasks, grading, and lesson planning can also be streamlined, allowing educators to devote more time to creativity and mentorship.</p>
                    <p class="text-rose-300">Yet these same tools may also create over-reliance on algorithms at the expense of genuine human connection. If education becomes too standardized through AI, it risks flattening the diversity of thought and creativity that comes from teacher-student interaction. Privacy is also a concern, since these systems often collect sensitive learning data. Finally, unequal access to technology could deepen the digital divide, leaving some students far behind.</p>
                </section>

                <section class="glass-card p-6 rounded-xl">
                    <h2 class="text-2xl font-bold mb-4">Coding with AI</h2>
                    <p class="text-emerald-300 mb-3">For developers, AI coding assistants can act like super-powered colleagues—suggesting snippets, debugging code, and speeding up routine tasks. Beginners benefit from real-time help, while professionals can focus on higher-level architecture and creative problem-solving. This lowers barriers to entry and accelerates innovation across the tech industry.</p>
                    <p class="text-rose-300">But the risks are real: AI-generated code can sometimes be incorrect, insecure, or opaque, making debugging harder in the long run. Over-reliance could erode developers’ own skills, while questions of copyright and intellectual property remain unresolved. There is also the risk of homogenization, where different developers lean too heavily on the same AI outputs, reducing diversity and creativity in software solutions.</p>
                </section>
            </div>
        </div>
    </main>
    <script src="../assets/js/script.js"></script>
</body>
</html>


